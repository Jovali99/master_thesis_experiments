{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fb0233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math \n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "from src.utils import print_yaml, rescale_logits, calculate_tau, plot_with_band, plot_bootstrap_band, pick_weighted_models, calculate_group_roc_pooled, plot_roc, plot_pareto, calculate_group_roc_pooled\n",
    "from src.save_load import savePlot, loadFbdStudy, loadTargetSignals, loadShadowModelSignals, saveVisData, loadVisData\n",
    "from LeakPro.leakpro.attacks.mia_attacks.lira import lira_vectorized\n",
    "from LeakPro.leakpro.attacks.mia_attacks.rmia import rmia_vectorised, rmia_get_gtlprobs\n",
    "from src.save_load import savePlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56bb882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------- #\n",
    "#   Load fbd study results   #\n",
    "# -------------------------- #\n",
    "study_name = \"cifar10-resnet-fbd-00c3fdac98\"\n",
    "study_type = study_name.split(\"-\")[2]\n",
    "study_path = os.path.join(\"study\", study_type+\"_studies\") \n",
    "metadata = []\n",
    "gtl_probs = []\n",
    "resc_logits = []\n",
    "# If path is removed it will attempt to load the study from \"study/...\"\n",
    "metadata, fbd_trial_results, gtl_probs, resc_logits, labels = loadFbdStudy(study_name, metadata=True, gtl=True, logits=True, path=study_path)\n",
    "target_folder = metadata[\"study\"][\"target_folder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13da03b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------- #\n",
    "#   Load baseline target signals   #\n",
    "# -------------------------------- #\n",
    "target_folder = metadata[\"study\"][\"target_folder\"]\n",
    "\n",
    "baseline_logits, baseline_inmask, baseline_resc_logits, baseline_gtl_probs, baseline_metadata, baseline_metadata_pkl = loadTargetSignals(target_folder)\n",
    "\n",
    "# Rescale baseline target logits\n",
    "if baseline_resc_logits is None and baseline_logits is not None:\n",
    "    baseline_resc_logits = rescale_logits(baseline_logits, labels)\n",
    "print(f\"Baseline resc_logits: {baseline_resc_logits[:10]}, shape: {baseline_resc_logits.shape}\")\n",
    "\n",
    "# Calculate the GTL Probabilities for the target logits\n",
    "if baseline_gtl_probs is None and baseline_logits is not None:\n",
    "    baseline_gtl_probs = rmia_get_gtlprobs(baseline_logits, labels)\n",
    "print(f\"Target gtl_probs: {baseline_gtl_probs[:10]}, shape: {baseline_gtl_probs.shape}\")\n",
    "\n",
    "baseline_accuracy = baseline_metadata_pkl.test_result.accuracy\n",
    "print(f\"Baseline accuracy: {baseline_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0f489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- #\n",
    "#   Load shadow model signals   #\n",
    "# ----------------------------- #\n",
    "shadow_logits, rescaled_shadow_logits, shadow_gtl_probs, shadow_inmask, sm_metadata, missing_indices = loadShadowModelSignals(target_folder)\n",
    "\n",
    "# Rescale and calc gtl for shadow models\n",
    "# rescaled_shadow_logits and shadow_gtl_probs will be false if they are not loaded\n",
    "if rescaled_shadow_logits is False or shadow_gtl_probs is False:\n",
    "    N, M, C = shadow_logits.shape\n",
    "    shadow_gtl_probs_list = []\n",
    "    rescaled_shadow_logits_list = []\n",
    "    for m in range(M):\n",
    "        model_logits = shadow_logits[:, m, :]  # shape (N, C)\n",
    "        \n",
    "        if not shadow_gtl_probs:\n",
    "            shadow_gtl_probs_list.append(rmia_get_gtlprobs(model_logits, labels))\n",
    "        if not rescaled_shadow_logits:\n",
    "            rescaled_shadow_logits_list.append(rescale_logits(model_logits, labels))\n",
    "            \n",
    "        print(f\"{len(shadow_gtl_probs_list)} shadow gtl probs calculated and {len(rescaled_shadow_logits_list)} rescaled logits calculated\")\n",
    "    \n",
    "    if not shadow_gtl_probs:    \n",
    "        shadow_gtl_probs = np.stack(shadow_gtl_probs_list, axis=1)  # shape = (N, M)\n",
    "    if not rescaled_shadow_logits:\n",
    "        rescaled_shadow_logits = np.stack(rescaled_shadow_logits_list, axis=1)\n",
    "    \n",
    "print(f\"shadow gtl probs shape: {shadow_gtl_probs.shape}, shadow resc logits shape: {rescaled_shadow_logits.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9143e769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- #\n",
    "#   Audit the baseline target   #\n",
    "# ----------------------------- #\n",
    "# Audit the baseline target with LiRA\n",
    "lira_scores = lira_vectorized(baseline_resc_logits, rescaled_shadow_logits, shadow_inmask, \"carlini\", online=True)\n",
    "print(f\"lira_scores first 10: {lira_scores[:10]}\")\n",
    "# Audit the baseline target with RMIA\n",
    "rmia_scores = rmia_vectorised(baseline_gtl_probs, shadow_gtl_probs, shadow_inmask, online=True, use_gpu_if_available=True)\n",
    "print(f\"rmia_scores first 10: {rmia_scores[:10]}\")\n",
    "\n",
    "# ------------------------------------- #\n",
    "#   Audit or Load the weighted target   #\n",
    "# ------------------------------------- #\n",
    "data = loadVisData(study_name, study_path=study_path)  # If study_path is removed it will attempt to load the study from \"study/...\"\n",
    "\n",
    "# Audit all weighted models with RMIA\n",
    "if data.get('w_rmia_scores') is None:\n",
    "    weighted_rmia_scores = []\n",
    "    for gtl in tqdm(gtl_probs, desc=f\"gtl_probs\"):\n",
    "        weighted_rmia_scores.append(rmia_vectorised(gtl, shadow_gtl_probs, shadow_inmask, online=True, use_gpu_if_available=True))\n",
    "    saveVisData(np.stack(weighted_rmia_scores, axis=0), \"w_rmia_scores\", study_name, path=study_path)\n",
    "else:\n",
    "    weighted_rmia_scores = data.get('w_rmia_scores')\n",
    "# Audit all weighted models with RMIA\n",
    "if data.get('w_lira_scores') is None:\n",
    "    weighted_lira_scores = []\n",
    "    for resc_logits in tqdm(resc_logits, desc=f\"resc_logits\"):\n",
    "        weighted_lira_scores.append(lira_vectorized(resc_logits, rescaled_shadow_logits, shadow_inmask, \"carlini\", online=True))\n",
    "    saveVisData(np.stack(weighted_lira_scores, axis=0), \"w_lira_scores\", study_name, path=study_path)\n",
    "else:\n",
    "    weighted_lira_scores = data.get('w_lira_scores')\n",
    "    \n",
    "print(f\"rmia_scores_weighted count: {len(weighted_rmia_scores)}\")\n",
    "print(f\"lira_scores_weighted count: {len(weighted_lira_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56065b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- #\n",
    "#   Calculate tau   #\n",
    "# ----------------- #\n",
    "# Baseline\n",
    "fpr1 = 0.1\n",
    "fpr2 = 0.01\n",
    "fpr3 = 0.001\n",
    "tau_baseline_rmia_1 = calculate_tau(rmia_scores, baseline_inmask, fpr1)\n",
    "tau_baseline_rmia_2 = calculate_tau(rmia_scores, baseline_inmask, fpr2)\n",
    "tau_baseline_rmia_3 = calculate_tau(rmia_scores, baseline_inmask, fpr3)\n",
    "\n",
    "tau_baseline_lira_1 = calculate_tau(lira_scores, baseline_inmask, fpr1)\n",
    "tau_baseline_lira_2 = calculate_tau(lira_scores, baseline_inmask, fpr2)\n",
    "tau_baseline_lira_3 = calculate_tau(lira_scores, baseline_inmask, fpr3)\n",
    "\n",
    "print(f\"baseline tau rmia_1: {tau_baseline_rmia_1} at fpr: {fpr1}\")\n",
    "print(f\"baseline tau lira_1: {tau_baseline_lira_1} at fpr: {fpr1}\")\n",
    "\n",
    "# Weighted 0.1 fpr\n",
    "weigted_taus_rmia_1 = []\n",
    "weigted_taus_lira_1 = []\n",
    "weigted_taus_rmia_2 = []\n",
    "weigted_taus_lira_2 = []\n",
    "weigted_taus_rmia_3 = []\n",
    "weigted_taus_lira_3 = []\n",
    "\n",
    "# --- RMIA ---\n",
    "rmia_scores_count = 1\n",
    "for w_rmia_score in tqdm(weighted_rmia_scores, desc=f\"w_rmia_scores\"):\n",
    "    weigted_taus_rmia_1.append(calculate_tau(w_rmia_score, baseline_inmask, fpr1))\n",
    "    weigted_taus_rmia_2.append(calculate_tau(w_rmia_score, baseline_inmask, fpr2))\n",
    "    weigted_taus_rmia_3.append(calculate_tau(w_rmia_score, baseline_inmask, fpr3))\n",
    "print(f\"n rmia taus: {weigted_taus_rmia_1[:5]}, {weigted_taus_rmia_2[:5]}, {weigted_taus_rmia_3[:5]}\")\n",
    "\n",
    "# --- LIRA ---\n",
    "lira_scores_count = 1\n",
    "for w_lira_score in tqdm(weighted_lira_scores, desc=f\"w_lira_scores\"):\n",
    "    weigted_taus_lira_1.append(calculate_tau(w_lira_score, baseline_inmask, fpr1))\n",
    "    weigted_taus_lira_2.append(calculate_tau(w_lira_score, baseline_inmask, fpr2))\n",
    "    weigted_taus_lira_3.append(calculate_tau(w_lira_score, baseline_inmask, fpr3))\n",
    "print(f\"n lira taus: {weigted_taus_lira_1[:5]}, {weigted_taus_lira_2[:5]}, {weigted_taus_lira_3[:5]}\")\n",
    "\n",
    "# Study outputs\n",
    "accuracies = [res.accuracy for res in fbd_trial_results]\n",
    "noises = [res.noise for res in fbd_trial_results]\n",
    "centralities = [res.centrality for res in fbd_trial_results]\n",
    "temperatures = [res.temperature for res in fbd_trial_results]\n",
    "tau_rmia = [res.tau for res in fbd_trial_results]   # tau in this context is log(tauc_fbd@0.1/tauc_ref@0.1)\n",
    "print(f\"study tau: {tau_rmia[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82db66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- #\n",
    "#   Scatter plots   #\n",
    "# ----------------- #\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 5))\n",
    "# --- Top-left: your study tau (FbD) --- #\n",
    "ax = axes[0,0]\n",
    "ax.scatter(tau_rmia, accuracies, label=\"FbD study\", color=\"purple\")\n",
    "ax.set_xlabel(\"Study Objective: log(tauc_fbd@0.1 / tauc_ref@0.1)\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(loc=\"lower right\")\n",
    "\n",
    "# --- Top-right: tau@0.1 for RMIA + LIRA --- #\n",
    "ax = axes[0,1]\n",
    "ax.scatter(weigted_taus_rmia_1, accuracies, label=\"RMIA on FbD\", color=\"cornflowerblue\", marker='o')\n",
    "ax.scatter(weigted_taus_lira_1, accuracies, label=\"LIRA on FbD\", color=\"orange\", marker='x')\n",
    "ax.scatter(tau_baseline_rmia_1, baseline_accuracy, label=\"RMIA on Baseline\", color=\"red\", marker='o')\n",
    "ax.scatter(tau_baseline_lira_1, baseline_accuracy, label=\"LIRA on Baseline\", color=\"green\", marker='x')\n",
    "ax.set_xlabel(\"τ@0.1FPR\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(loc=\"lower right\")\n",
    "\n",
    "# --- Bottom-left: tau@0.01 --- #\n",
    "ax = axes[1,0]\n",
    "ax.scatter(weigted_taus_rmia_2, accuracies, label=\"RMIA on FbD\", color=\"cornflowerblue\", marker='o')\n",
    "ax.scatter(weigted_taus_lira_2, accuracies, label=\"LIRA on FbD\", color=\"orange\", marker='x')\n",
    "ax.scatter(tau_baseline_rmia_2, baseline_accuracy, label=\"RMIA on Baseline\", color=\"red\", marker='o')\n",
    "ax.scatter(tau_baseline_lira_2, baseline_accuracy, label=\"LIRA on Baseline\", color=\"green\", marker='x')\n",
    "ax.set_xlabel(\"τ@0.01FPR\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(loc=\"lower right\")\n",
    "\n",
    "# --- Bottom-right: tau@0.001 --- #\n",
    "ax = axes[1,1]\n",
    "ax.scatter(weigted_taus_rmia_3, accuracies, label=\"RMIA on FbD\", color=\"cornflowerblue\", marker='o')\n",
    "ax.scatter(weigted_taus_lira_3, accuracies, label=\"LIRA on FbD\", color=\"orange\", marker='x')\n",
    "ax.scatter(tau_baseline_rmia_3, baseline_accuracy, label=\"RMIA on Baseline\", color=\"red\", marker='o')\n",
    "ax.scatter(tau_baseline_lira_3, baseline_accuracy, label=\"LIRA on Baseline\", color=\"green\", marker='x')\n",
    "ax.set_xlabel(\"τ@0.001FPR\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(loc=\"lower right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "savePlot(fig, \"Scatter_plots\", study_name, study_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a88c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- #\n",
    "#   Create Dataframe   #\n",
    "# -------------------- #\n",
    "df = pd.DataFrame({\n",
    "    \"accuracy\": accuracies,\n",
    "\n",
    "    \"study\": np.arange(len(noises))+1,\n",
    "\n",
    "    # RMIA / LiRA taus at different FPRs\n",
    "    \"tau_0.1_rmia\": weigted_taus_rmia_1,\n",
    "    \"tau_0.1_lira\": weigted_taus_lira_1,\n",
    "\n",
    "    \"tau_0.01_rmia\": weigted_taus_rmia_2,\n",
    "    \"tau_0.01_lira\": weigted_taus_lira_2,\n",
    "\n",
    "    \"tau_0.001_rmia\": weigted_taus_rmia_3,\n",
    "    \"tau_0.001_lira\": weigted_taus_lira_3,\n",
    "\n",
    "    # Hyperparameters\n",
    "    \"noise\": noises,\n",
    "    \"centrality\": centralities,\n",
    "    \"temperature\": temperatures,\n",
    "})\n",
    "df = df.reset_index(drop=True)\n",
    "df[\"model_idx\"] = df.index\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673f2fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- #\n",
    "#   Create FbD Param Groups   #\n",
    "# --------------------------- #\n",
    "fbd_grps = (\n",
    "    df.groupby([\"noise\", \"centrality\", \"temperature\"])\n",
    "    .agg(\n",
    "        accuracy_mean=(\"accuracy\", \"mean\"),\n",
    "        accuracy_std=(\"accuracy\", \"std\"),\n",
    "\n",
    "        noise_mean=(\"noise\", \"mean\"),\n",
    "        noise_std=(\"noise\", \"std\"),\n",
    "        \n",
    "        centrality_mean=(\"centrality\", \"mean\"),\n",
    "        centrality_std=(\"centrality\", \"std\"),\n",
    "        \n",
    "        temperature_mean=(\"temperature\", \"mean\"),\n",
    "        temperature_std=(\"temperature\", \"std\"),\n",
    "        model_indices=(\"model_idx\", list),\n",
    "        n=(\"study\", \"size\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "fbd_grps[[\"noise\", \"centrality\", \"temperature\"]] = (fbd_grps[[\"noise\", \"centrality\", \"temperature\"]].round(3))\n",
    "fbd_grps = fbd_grps.set_index([\"noise\", \"centrality\", \"temperature\"])\n",
    "\n",
    "print(fbd_grps.shape)\n",
    "group_threshold = 7\n",
    "fbd_grps = fbd_grps[fbd_grps[\"n\"]>=group_threshold]\n",
    "print(fbd_grps.shape)\n",
    "fbd_grps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da63e26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------- #\n",
    "#   Calculate FbD Param groups ROC   #\n",
    "# ---------------------------------- #\n",
    "# Calculate the baseline curves\n",
    "baseline_fpr_curve_lira, baseline_tpr_curve_lira, _ = roc_curve(baseline_inmask, lira_scores)\n",
    "baseline_fpr_curve_rmia, baseline_tpr_curve_rmia, _ = roc_curve(baseline_inmask, rmia_scores)\n",
    "# ------------------------- Select groups ------------------------- #\n",
    "groups = []\n",
    "groups.append(fbd_grps.loc[(0.000, 0.40, 0.15)])\n",
    "groups.append(fbd_grps.loc[(0.000, 0.40, 0.00)])\n",
    "groups.append(fbd_grps.loc[(0.030, 0.40, 0.00)])\n",
    "# ---------------------- Collect group scores ---------------------- #\n",
    "grp_lira_scores_list = []\n",
    "grp_rmia_scores_list = []\n",
    "for grp in groups:\n",
    "    grp_lira_scores_list.append([weighted_rmia_scores[i] for i in grp[\"model_indices\"]])\n",
    "    grp_rmia_scores_list.append([weighted_lira_scores[i] for i in grp[\"model_indices\"]])\n",
    "# --------------- Calculate accuracy band group ROCs --------------- #\n",
    "# LiRA & RMIA scores\n",
    "lira_fpr_curves, lira_tpr_curves = [], []\n",
    "rmia_fpr_curves, rmia_tpr_curves = [], []\n",
    "for l_scores, r_scores in zip(grp_lira_scores_list, grp_rmia_scores_list):\n",
    "    l_fpr, l_tpr = calculate_group_roc_pooled(l_scores, baseline_inmask)\n",
    "    lira_fpr_curves.append(l_fpr)\n",
    "    lira_tpr_curves.append(l_tpr)\n",
    "\n",
    "    r_fpr, r_tpr = calculate_group_roc_pooled(r_scores, baseline_inmask)\n",
    "    rmia_fpr_curves.append(r_fpr)\n",
    "    rmia_tpr_curves.append(r_tpr)\n",
    "\n",
    "# --------------- Create Plots --------------- #\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "labels = []\n",
    "for grp in groups:\n",
    "    noise, centrality, temperature = grp.name\n",
    "    labels.append(f\"FbD: σ={noise:.3f}, c={centrality:.1f}, t={temperature:.2f}, ā={grp['accuracy_mean']:.2f}\")\n",
    "    \n",
    "# --------------- LiRA Plot --------------- #\n",
    "plot_roc(ax=axes[0], fpr_curves=lira_fpr_curves, tpr_curves=lira_tpr_curves, labels=labels, \n",
    "         b_fpr=baseline_fpr_curve_lira, b_tpr=baseline_tpr_curve_lira, b_label=f\"Baseline: a={baseline_accuracy:.2f}\", \n",
    "         title=\"LiRA ROC Curves\")\n",
    "# --------------- RMIA Plot --------------- #\n",
    "plot_roc(ax=axes[1], fpr_curves=rmia_fpr_curves, tpr_curves=rmia_tpr_curves, labels=labels, \n",
    "         b_fpr=baseline_fpr_curve_lira, b_tpr=baseline_tpr_curve_lira, b_label=f\"Baseline: a={baseline_accuracy:.2f}\", \n",
    "         title=\"RMIA ROC Curves\")\n",
    "plt.show()\n",
    "\n",
    "group_title = \"roc_fbd_groups\"\n",
    "plot_path = os.path.join(os.path.join(study_path, study_name), \"plot\")\n",
    "save_path = os.path.join(plot_path, group_title + \".tex\")\n",
    "\n",
    "fbd_grps_rounded = fbd_grps.round({\n",
    "    \"accuracy_mean\": 3,\n",
    "    \"accuracy_std\": 4,\n",
    "    \"noise_mean\": 4,\n",
    "    \"noise_std\": 4,\n",
    "    \"centrality_mean\": 3,\n",
    "    \"centrality_std\": 3,\n",
    "    \"temperature_mean\": 3,\n",
    "    \"temperature_std\": 3\n",
    "})\n",
    "# Convert to LaTeX table\n",
    "latex_table = fbd_grps_rounded.to_latex(\n",
    "    index=True,             # keeps the acc_band as the first column\n",
    "    caption=\"FbD hyperparameter summary by accuracy band\",\n",
    "    label=\"tab:fbd_summary\",\n",
    "    float_format=\"%.3f\",    # ensures consistent decimal places\n",
    "    column_format=\"lccccccc\" # left for acc_band, centered for other columns\n",
    ")\n",
    "# Save to file\n",
    "with open(save_path, \"w\") as f:\n",
    "    f.write(latex_table)\n",
    "\n",
    "savePlot(fig, group_title, study_name, study_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baba4263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------ #\n",
    "#   Create & Calculate Pareto Groups   #\n",
    "# ------------------------------------ #\n",
    "group_001 = (\n",
    "    df.groupby([\"noise\", \"centrality\", \"temperature\"])\n",
    "    .agg(\n",
    "        accuracy_mean=(\"accuracy\", \"mean\"),\n",
    "        accuracy_std=(\"accuracy\", \"std\"),\n",
    "\n",
    "        rmia_mean=(\"tau_0.001_rmia\", \"mean\"),\n",
    "        rmia_std=(\"tau_0.001_rmia\", \"std\"),\n",
    "        rmia_median=(\"tau_0.001_rmia\", \"median\"),\n",
    "\n",
    "        lira_mean=(\"tau_0.001_lira\", \"mean\"),\n",
    "        lira_std=(\"tau_0.001_lira\", \"std\"),\n",
    "        lira_median=(\"tau_0.001_lira\", \"median\"),\n",
    "        \n",
    "        n=(\"study\", \"size\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "group_01 = (\n",
    "    df.groupby([\"noise\", \"centrality\", \"temperature\"])\n",
    "    .agg(\n",
    "        accuracy_mean=(\"accuracy\", \"mean\"),\n",
    "        accuracy_std=(\"accuracy\", \"std\"),\n",
    "\n",
    "        rmia_mean=(\"tau_0.01_rmia\", \"mean\"),\n",
    "        rmia_std=(\"tau_0.01_rmia\", \"std\"),\n",
    "        rmia_median=(\"tau_0.01_rmia\", \"median\"),\n",
    "\n",
    "        lira_mean=(\"tau_0.01_lira\", \"mean\"),\n",
    "        lira_std=(\"tau_0.01_lira\", \"std\"),\n",
    "        lira_median=(\"tau_0.01_lira\", \"median\"),\n",
    "        \n",
    "        n=(\"study\", \"size\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "group_1 = (\n",
    "    df.groupby([\"noise\", \"centrality\", \"temperature\"])\n",
    "    .agg(\n",
    "        accuracy_mean=(\"accuracy\", \"mean\"),\n",
    "        accuracy_std=(\"accuracy\", \"std\"),\n",
    "\n",
    "        rmia_mean=(\"tau_0.1_rmia\", \"mean\"),\n",
    "        rmia_std=(\"tau_0.1_rmia\", \"std\"),\n",
    "        rmia_median=(\"tau_0.1_rmia\", \"median\"),\n",
    "\n",
    "        lira_mean=(\"tau_0.1_lira\", \"mean\"),\n",
    "        lira_std=(\"tau_0.1_lira\", \"std\"),\n",
    "        lira_median=(\"tau_0.1_lira\", \"median\"),\n",
    "        \n",
    "        n=(\"study\", \"size\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "grps = [group_1, group_01, group_001]\n",
    "cut_group = []\n",
    "for grp in grps:\n",
    "    cut_group.append(grp[grp[\"n\"]>=3])\n",
    "\n",
    "paretos = []\n",
    "for c_grp in cut_group:\n",
    "    xy_groups = [\n",
    "        c_grp[[\"lira_mean\", \"accuracy_mean\"]].to_numpy(),\n",
    "        c_grp[[\"rmia_mean\", \"accuracy_mean\"]].to_numpy()\n",
    "    ]\n",
    "    tst_list = []\n",
    "    for xy, attack in zip(xy_groups, [\"lira\", \"rmia\"]):\n",
    "        n = xy.shape[0]\n",
    "        is_dominated = np.zeros(n, dtype=bool)\n",
    "    \n",
    "        for i in range(n):\n",
    "            # j dominates i if j has lower/equal x and higher/equal y,\n",
    "            # and strictly better in at least one objective\n",
    "            dominates_i = ((xy[:, 0] <= xy[i, 0]) & (xy[:, 1] >= xy[i, 1]) &\n",
    "                        ((xy[:, 0] < xy[i, 0]) | (xy[:, 1] > xy[i, 1])))\n",
    "            is_dominated[i] = np.any(dominates_i)\n",
    "    \n",
    "        frontier_mask = ~is_dominated\n",
    "        if attack == \"lira\":\n",
    "            tst = c_grp.loc[frontier_mask].sort_values(\"lira_mean\")\n",
    "        elif attack == \"rmia\":\n",
    "            tst = c_grp.loc[frontier_mask].sort_values(\"rmia_mean\")\n",
    "            \n",
    "        tst_list.append(tst)\n",
    "    paretos.append(tst_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdf290d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- #\n",
    "#  Group Pareto Visualization #\n",
    "# --------------------------- #\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "plot_pareto(ax=axes[0], cut_group=cut_group[0], paretos=paretos[0], grp_fpr=0.1)\n",
    "plot_pareto(ax=axes[1], cut_group=cut_group[1], paretos=paretos[1], grp_fpr=0.01)\n",
    "fig = plt.gcf()\n",
    "fig.show()\n",
    "savePlot(fig, f\"pareto_frontiers\", study_name, study_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
