{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247c0c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import pickle\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import src.study_handler as sh\n",
    "from src.utils import print_yaml, get_shadow_signals, calculate_tauc\n",
    "from LeakPro.leakpro.attacks.mia_attacks.rmia import rmia_vectorised, rmia_get_gtlprobs\n",
    "from src.save_load import loadTargetSignals, loadShadowModelSignals\n",
    "from src.models.resnet18_model import ResNet18\n",
    "from src.optimize_fbd_model import parallell_optimization\n",
    "from src.dataclasses import FbdArgs\n",
    "from src.dataset_handler import processDataset, loadDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cad8e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------#\n",
    "#  Load Study Config  #\n",
    "#---------------------#\n",
    "config = None\n",
    "with open(\"./study_fbd.yaml\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "print_yaml(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bf4d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------#\n",
    "#  Load Model Signals  #\n",
    "#----------------------#\n",
    "target_folder = config[\"fbd_study\"][\"target_folder\"]\n",
    "\n",
    "# Load target signals\n",
    "target_logits, target_inmask, resc_logits, target_gtl_probs, metadata, metadata_pkl = loadTargetSignals(target_folder)\n",
    "\n",
    "# Load processed shadow model signals\n",
    "what_to_load = {\n",
    "    \"logits\": False,\n",
    "    \"resc_logits\": False,\n",
    "    \"gtl_probs\": True,\n",
    "    \"in_mask\": True,\n",
    "    \"metadata_pkl\": False\n",
    "}\n",
    "# The missing indices variable will contain a list of all indices not found up to the set amount of shadow models\n",
    "shadow_logits, sm_resc_logits, shadow_gtl_probs, shadow_inmask, sm_metadata_pkl, missing_indices = loadShadowModelSignals(target_folder, what_to_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b79ad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------#\n",
    "#  Update Study Config  #\n",
    "#-----------------------#\n",
    "print_yaml(\"------------ Initial study config: ------------\")\n",
    "print_yaml(config['fbd_study'])\n",
    "train_metadata = metadata[\"train\"]\n",
    "\n",
    "config['fbd_study'][\"epochs\"] = train_metadata[\"epochs\"]\n",
    "config['fbd_study'][\"batch_size\"] = train_metadata[\"batch_size\"]\n",
    "config['fbd_study'][\"momentum\"] = train_metadata[\"momentum\"]\n",
    "config['fbd_study'][\"learning_rate\"] = train_metadata[\"learning_rate\"]\n",
    "config['fbd_study'][\"t_max\"] = train_metadata[\"t_max\"]\n",
    "config['fbd_study'][\"weight_decay\"] = train_metadata[\"weight_decay\"]\n",
    "config['fbd_study'][\"model\"] = train_metadata[\"model\"]\n",
    "config['fbd_study'][\"optimizer\"] = train_metadata[\"optimizer\"]\n",
    "config['fbd_study'][\"drop_rate\"] = train_metadata[\"drop_rate\"] \n",
    "\n",
    "# Build the study name\n",
    "config[\"fbd_study\"][\"study_name\"] = f'{config[\"data\"][\"dataset\"]}-{train_metadata[\"model\"]}-fbd'\n",
    "\n",
    "\n",
    "print_yaml(\"\\n------------ Updated study config: ------------\")\n",
    "print_yaml(config['fbd_study'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce50bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------#\n",
    "#  Select Shadow Models  #\n",
    "#------------------------#\n",
    "sel_sm = False\n",
    "if sel_sm:\n",
    "    sm_count = config['fbd_study']['shadow_model_count']\n",
    "    print(f\"Randomly selecting {sm_count} to be used for the study.\")\n",
    "    shadow_logits, shadow_inmask = get_shadow_signals(shadow_logits, shadow_inmask, sm_count)\n",
    "    print(f\"Shape of selected_sm_logits: {shadow_logits.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b378b9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------#\n",
    "#  Prepare dataset  #\n",
    "#-------------------#\n",
    "data_cfg = config['data']\n",
    "trainset, testset, full_dataset = loadDataset(data_cfg)\n",
    "\n",
    "# Will split the dataset to use the same in indices as the baseline target model\n",
    "train_dataset, test_dataset, train_indices, test_indices = processDataset(data_cfg, trainset, testset, in_indices_mask=target_inmask, dataset=full_dataset)\n",
    "\n",
    "# Retrieve the targets\n",
    "full_dataset = train_dataset.dataset\n",
    "labels = full_dataset.targets\n",
    "print(f\"Length of dataset targets/labels: {len(labels)}\")\n",
    "print(f\"First 10 targets/labels: {labels[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ccc16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------#\n",
    "#  Calculate Vulnerability score using RMIA  #\n",
    "#--------------------------------------------#\n",
    "# Calculate the GTL Probabilities for shadow model logits\n",
    "calc_sm_gtl = False\n",
    "if calc_sm_gtl:\n",
    "    N, M, C = shadow_logits.shape\n",
    "    shadow_gtl_probs_list = []\n",
    "    \n",
    "    for m in range(M):\n",
    "        model_logits = shadow_logits[:, m, :]  # shape (N, C)\n",
    "        probs = rmia_get_gtlprobs(model_logits, labels)\n",
    "        shadow_gtl_probs_list.append(probs)\n",
    "        print(f\"{len(shadow_gtl_probs_list)} shadow gtl probs calculated\")\n",
    "\n",
    "    shadow_gtl_probs = np.stack(shadow_gtl_probs_list, axis=1)  # shape = (N, M)\n",
    "print(f\"Shadow Model gtl probs shape: {shadow_gtl_probs.shape}\")\n",
    "\n",
    "# Calculate the GTL Probabilities for the target logits\n",
    "calc_targ_gtl = False\n",
    "if calc_targ_gtl:\n",
    "    target_gtl_probs = rmia_get_gtlprobs(target_logits, labels)\n",
    "print(f\"Target gtl_probs: {target_gtl_probs[:10]}, shape: {target_gtl_probs.shape}\")\n",
    "\n",
    "# Calulate the reference RMIA score\n",
    "rmia_scores = rmia_vectorised(target_gtl_probs, shadow_gtl_probs, shadow_inmask, online=True, use_gpu_if_available=True)\n",
    "\n",
    "#----------------------------#\n",
    "#  Calculate Reference TAUC  #\n",
    "#----------------------------#\n",
    "# Reference tail AUC at fpr=0.1\n",
    "tauc_ref = calculate_tauc(rmia_scores, target_inmask, fpr=0.1)\n",
    "print(f\"tauc_ref@(0.1): {tauc_ref}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34eca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------#\n",
    "#        Run study        #\n",
    "# ------------------------#\n",
    "\n",
    "fbd_args = FbdArgs(\n",
    "    rmia_scores=rmia_scores,\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    shadow_gtl_probs=shadow_gtl_probs,\n",
    "    shadow_inmask=shadow_inmask,\n",
    "    target_inmask=target_inmask,\n",
    "    tauc_ref=tauc_ref,\n",
    ")\n",
    "\n",
    "gpu_ids = [0, 1, 2, 3, 4, 5, 6]\n",
    "\n",
    "if config is not None: \n",
    "    study = parallell_optimization(config, labels, fbd_args, gpu_ids, study_hash=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9211a6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from_db = True\n",
    "if load_from_db:\n",
    "    study_cfg = config['fbd_study'] \n",
    "    db_path = os.path.join(study_cfg['root'], \"fbd_study.db\")\n",
    "    storage = f\"sqlite:///{db_path}\"\n",
    "    study = optuna.load_study(study_name=\"cifar10-resnet-fbd-815409b641\", storage=storage)\n",
    "\n",
    "if study is not None:\n",
    "    print(\"visualizing study\")\n",
    "    fig1 = optuna.visualization.plot_pareto_front(study)\n",
    "    fig1.update_layout(xaxis_title=\"Ï„@0.1\", yaxis_title=\"Accuracy\")\n",
    "    fig1.show()\n",
    "\n",
    "    fig2 = optuna.visualization.plot_param_importances(study)\n",
    "    fig2.show()\n",
    "else:\n",
    "    print(\"Study has not been run\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
